{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 7 - Federated Learning with Federated Dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Polarbeargo/PySyft/blob/master/examples/tutorials/Part%207%20-%20Federated%20Learning%20with%20Federated%20Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eecq1MwL6twY",
        "colab_type": "text"
      },
      "source": [
        "# Part 7 - Federated Learning with FederatedDataset\n",
        "\n",
        "Here we introduce a new tool for using federated datasets. We have created a `FederatedDataset` class which is intended to be used like the PyTorch Dataset class, and is given to a federated data loader `FederatedDataLoader` which will iterate on it in a federated fashion.\n",
        "\n",
        "\n",
        "Authors:\n",
        "- Andrew Trask - Twitter: [@iamtrask](https://twitter.com/iamtrask)\n",
        "- Théo Ryffel - GitHub: [@LaRiffle](https://github.com/LaRiffle)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksGOfcIm6vTp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1295
        },
        "outputId": "787d75b3-2106-42df-c8cb-5f1a6d6cd4cd"
      },
      "source": [
        "!pip install syft"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting syft\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/ad/cd2d1d63f87d69b4764b8bb2898713e638355d654660355b7b7134ca78a8/syft-0.1.17-py3-none-any.whl (176kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: Flask in /usr/local/lib/python3.6/dist-packages (from syft) (1.0.3)\n",
            "Collecting flask-socketio (from syft)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/68/fe4806d3a0a5909d274367eb9b3b87262906c1515024f46c2443a36a0c82/Flask_SocketIO-4.1.0-py2.py3-none-any.whl\n",
            "Collecting tf-encrypted>=0.5.4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/f0/b37654fcfe14711509a5d2517b22688f091254491005e4d243f67e726455/tf_encrypted-0.5.4-py3-none-manylinux1_x86_64.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 49.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tblib in /usr/local/lib/python3.6/dist-packages (from syft) (1.4.0)\n",
            "Requirement already satisfied: torch>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from syft) (1.1.0)\n",
            "Collecting websocket-client (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/19/44753eab1fdb50770ac69605527e8859468f3c0fd7dc5a76dd9c4dbd7906/websocket_client-0.56.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 53.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from syft) (0.3.0)\n",
            "Collecting lz4 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0a/c6/96bbb3525a63ebc53ea700cc7d37ab9045542d33b4d262d0f0408ad9bbf2/lz4-2.1.10-cp36-cp36m-manylinux1_x86_64.whl (385kB)\n",
            "\u001b[K     |████████████████████████████████| 389kB 42.0MB/s \n",
            "\u001b[?25hCollecting websockets>=7.0 (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/71/8bfa882b9c502c36e5c9ef6732969533670d2b039cbf95a82ced8f762b80/websockets-7.0-cp36-cp36m-manylinux1_x86_64.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 27.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack in /usr/local/lib/python3.6/dist-packages (from syft) (0.5.6)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from syft) (0.0)\n",
            "Collecting zstd (from syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/27/1ea8086d37424e83ab692015cc8dd7d5e37cf791e339633a40dc828dfb74/zstd-1.4.0.0.tar.gz (450kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 50.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.6/dist-packages (from Flask->syft) (2.10.1)\n",
            "Requirement already satisfied: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from Flask->syft) (7.0)\n",
            "Requirement already satisfied: Werkzeug>=0.14 in /usr/local/lib/python3.6/dist-packages (from Flask->syft) (0.15.4)\n",
            "Requirement already satisfied: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from Flask->syft) (1.1.0)\n",
            "Collecting python-socketio>=2.1.0 (from flask-socketio->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/e0/a875abbb0f9d70c6e2ec2019ca9e3893377cef5deca6225ead3497000152/python_socketio-4.1.0-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 21.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.16.4)\n",
            "Collecting pyyaml>=5.1 (from tf-encrypted>=0.5.4->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/837fefac7475963d1eccf4aa684c23b95aa6c1d033a2c5965ccb11e22623/PyYAML-5.1.1.tar.gz (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 51.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-encrypted>=0.5.4->syft) (1.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client->syft) (1.12.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->syft) (4.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->syft) (0.21.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10->Flask->syft) (1.1.1)\n",
            "Collecting python-engineio>=3.8.0 (from python-socketio>=2.1.0->flask-socketio->syft)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/d3/de0fa7ebebd054de308e6ac397bf9e11ea42924795a38005a21ea001b114/python_engineio-3.8.1-py2.py3-none-any.whl (119kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 49.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.7.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.7.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.33.4)\n",
            "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.13.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.0.8)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.13.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (0.8.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision->syft) (0.46)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->syft) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->syft) (0.13.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (41.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.1.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (2.8.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow<2,>=1.12.0->tf-encrypted>=0.5.4->syft) (3.0.5)\n",
            "Building wheels for collected packages: zstd, pyyaml\n",
            "  Building wheel for zstd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/9a/f4/3105b5209674ac77fcca7fede95184c62a95df0196888e0e76\n",
            "  Building wheel for pyyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/27/a1/775c62ddea7bfa62324fd1f65847ed31c55dadb6051481ba3f\n",
            "Successfully built zstd pyyaml\n",
            "Installing collected packages: python-engineio, python-socketio, flask-socketio, pyyaml, tf-encrypted, websocket-client, lz4, websockets, zstd, syft\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed flask-socketio-4.1.0 lz4-2.1.10 python-engineio-3.8.1 python-socketio-4.1.0 pyyaml-5.1.1 syft-0.1.17 tf-encrypted-0.5.4 websocket-client-0.56.0 websockets-7.0 zstd-1.4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOmblm5m6twa",
        "colab_type": "text"
      },
      "source": [
        "We use the sandbox that we discovered last lesson"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzL-OfjR6twb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b674ee0d-7051-4af2-9df7-4ef344cee3d2"
      },
      "source": [
        "import torch as th\n",
        "import syft as sy\n",
        "sy.create_sandbox(globals(), verbose=False)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting up Sandbox...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ-9DPrx6twh",
        "colab_type": "text"
      },
      "source": [
        "Then search for a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNYBBuDG6twh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "boston_data = grid.search(\"#boston\", \"#data\", verbose=False, return_counter=False)\n",
        "boston_target = grid.search(\"#boston\", \"#target\", verbose=False, return_counter=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_GV3lQY6twj",
        "colab_type": "text"
      },
      "source": [
        "We load a model and an optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8f7HJlx6twk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_features = boston_data['alice'][0].shape[1]\n",
        "n_targets = 1\n",
        "model = th.nn.Linear(n_features, n_targets)\n",
        "optimizer = th.optim.SGD(params=model.parameters(),lr=0.0000001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rBIu5JN6twm",
        "colab_type": "text"
      },
      "source": [
        "Here we cast the data fetched in a `FederatedDataset`. See the workers which hold part of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXjQUmVK6twn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d98b08a-a656-4454-a55f-ccecc4207c6a"
      },
      "source": [
        "# Cast the result in BaseDatasets\n",
        "datasets = []\n",
        "for worker in boston_data.keys():\n",
        "    dataset = sy.BaseDataset(boston_data[worker][0], boston_target[worker][0])\n",
        "    datasets.append(dataset)\n",
        "\n",
        "# Build the FederatedDataset object\n",
        "dataset = sy.FederatedDataset(datasets)\n",
        "print(dataset.workers)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['bob', 'theo', 'jason', 'alice', 'andy', 'jon']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3jSUwJe6twq",
        "colab_type": "text"
      },
      "source": [
        "We put it in a `FederatedDataLoader` and specify options"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvB_Ew-A6twr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = sy.FederatedDataLoader(dataset, batch_size=4, shuffle=False, drop_last=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84kTRm-66twu",
        "colab_type": "text"
      },
      "source": [
        "And finally we iterate over epochs. You can see how similar this is compared to pure and local PyTorch training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "6N8LGnuk6twu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1377
        },
        "outputId": "5e5fda92-7fa2-4e68-c71d-46ee85574062"
      },
      "source": [
        "epochs = 10\n",
        "for epoch in range(1, epochs + 1):\n",
        "    loss_accum = 0\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        model.send(data.location)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        pred = model(data)\n",
        "        loss = ((pred - target)**2).sum()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        model.get()\n",
        "        loss = loss.get()\n",
        "        \n",
        "        loss_accum += float(loss)\n",
        "        \n",
        "        if batch_idx % 20 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * data.shape[0], len(train_loader),\n",
        "                       100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "            \n",
        "    print('Total loss', loss_accum)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/127 (0%)]\tLoss: 301401.562500\n",
            "Train Epoch: 1 [80/127 (16%)]\tLoss: 2114.468018\n",
            "Train Epoch: 1 [160/127 (31%)]\tLoss: 10344.879883\n",
            "Train Epoch: 1 [240/127 (47%)]\tLoss: 991.852783\n",
            "Train Epoch: 1 [320/127 (63%)]\tLoss: 210.898224\n",
            "Train Epoch: 1 [400/127 (79%)]\tLoss: 10101.279297\n",
            "Train Epoch: 1 [480/127 (94%)]\tLoss: 4210.054688\n",
            "Total loss 741109.0919494629\n",
            "Train Epoch: 2 [0/127 (0%)]\tLoss: 2385.207275\n",
            "Train Epoch: 2 [80/127 (16%)]\tLoss: 324.100708\n",
            "Train Epoch: 2 [160/127 (31%)]\tLoss: 7908.136230\n",
            "Train Epoch: 2 [240/127 (47%)]\tLoss: 1015.451782\n",
            "Train Epoch: 2 [320/127 (63%)]\tLoss: 144.818268\n",
            "Train Epoch: 2 [400/127 (79%)]\tLoss: 5754.004395\n",
            "Train Epoch: 2 [480/127 (94%)]\tLoss: 5770.668457\n",
            "Total loss 275168.7668952942\n",
            "Train Epoch: 3 [0/127 (0%)]\tLoss: 2143.198242\n",
            "Train Epoch: 3 [80/127 (16%)]\tLoss: 216.586853\n",
            "Train Epoch: 3 [160/127 (31%)]\tLoss: 7541.060547\n",
            "Train Epoch: 3 [240/127 (47%)]\tLoss: 992.328613\n",
            "Train Epoch: 3 [320/127 (63%)]\tLoss: 132.603836\n",
            "Train Epoch: 3 [400/127 (79%)]\tLoss: 5240.726074\n",
            "Train Epoch: 3 [480/127 (94%)]\tLoss: 5913.041504\n",
            "Total loss 260376.44496154785\n",
            "Train Epoch: 4 [0/127 (0%)]\tLoss: 2103.484863\n",
            "Train Epoch: 4 [80/127 (16%)]\tLoss: 214.377319\n",
            "Train Epoch: 4 [160/127 (31%)]\tLoss: 7453.000488\n",
            "Train Epoch: 4 [240/127 (47%)]\tLoss: 964.349487\n",
            "Train Epoch: 4 [320/127 (63%)]\tLoss: 127.137993\n",
            "Train Epoch: 4 [400/127 (79%)]\tLoss: 5195.007324\n",
            "Train Epoch: 4 [480/127 (94%)]\tLoss: 5826.008301\n",
            "Total loss 257749.57563781738\n",
            "Train Epoch: 5 [0/127 (0%)]\tLoss: 2093.031006\n",
            "Train Epoch: 5 [80/127 (16%)]\tLoss: 225.154953\n",
            "Train Epoch: 5 [160/127 (31%)]\tLoss: 7407.991699\n",
            "Train Epoch: 5 [240/127 (47%)]\tLoss: 937.790894\n",
            "Train Epoch: 5 [320/127 (63%)]\tLoss: 122.976814\n",
            "Train Epoch: 5 [400/127 (79%)]\tLoss: 5211.597168\n",
            "Train Epoch: 5 [480/127 (94%)]\tLoss: 5710.700195\n",
            "Total loss 256775.49631881714\n",
            "Train Epoch: 6 [0/127 (0%)]\tLoss: 2087.156738\n",
            "Train Epoch: 6 [80/127 (16%)]\tLoss: 237.566101\n",
            "Train Epoch: 6 [160/127 (31%)]\tLoss: 7371.105469\n",
            "Train Epoch: 6 [240/127 (47%)]\tLoss: 913.359009\n",
            "Train Epoch: 6 [320/127 (63%)]\tLoss: 119.321869\n",
            "Train Epoch: 6 [400/127 (79%)]\tLoss: 5231.844238\n",
            "Train Epoch: 6 [480/127 (94%)]\tLoss: 5597.248047\n",
            "Total loss 256040.9252796173\n",
            "Train Epoch: 7 [0/127 (0%)]\tLoss: 2082.153809\n",
            "Train Epoch: 7 [80/127 (16%)]\tLoss: 249.798401\n",
            "Train Epoch: 7 [160/127 (31%)]\tLoss: 7336.971680\n",
            "Train Epoch: 7 [240/127 (47%)]\tLoss: 890.950623\n",
            "Train Epoch: 7 [320/127 (63%)]\tLoss: 116.023346\n",
            "Train Epoch: 7 [400/127 (79%)]\tLoss: 5247.408691\n",
            "Train Epoch: 7 [480/127 (94%)]\tLoss: 5489.703613\n",
            "Total loss 255330.5668067932\n",
            "Train Epoch: 8 [0/127 (0%)]\tLoss: 2077.448730\n",
            "Train Epoch: 8 [80/127 (16%)]\tLoss: 261.519653\n",
            "Train Epoch: 8 [160/127 (31%)]\tLoss: 7304.673828\n",
            "Train Epoch: 8 [240/127 (47%)]\tLoss: 870.369202\n",
            "Train Epoch: 8 [320/127 (63%)]\tLoss: 113.028763\n",
            "Train Epoch: 8 [400/127 (79%)]\tLoss: 5257.516602\n",
            "Train Epoch: 8 [480/127 (94%)]\tLoss: 5388.236328\n",
            "Total loss 254609.00765228271\n",
            "Train Epoch: 9 [0/127 (0%)]\tLoss: 2072.941406\n",
            "Train Epoch: 9 [80/127 (16%)]\tLoss: 272.648468\n",
            "Train Epoch: 9 [160/127 (31%)]\tLoss: 7273.965332\n",
            "Train Epoch: 9 [240/127 (47%)]\tLoss: 851.425293\n",
            "Train Epoch: 9 [320/127 (63%)]\tLoss: 110.303490\n",
            "Train Epoch: 9 [400/127 (79%)]\tLoss: 5262.512207\n",
            "Train Epoch: 9 [480/127 (94%)]\tLoss: 5292.465820\n",
            "Total loss 253869.2348136902\n",
            "Train Epoch: 10 [0/127 (0%)]\tLoss: 2068.604736\n",
            "Train Epoch: 10 [80/127 (16%)]\tLoss: 283.157837\n",
            "Train Epoch: 10 [160/127 (31%)]\tLoss: 7244.714844\n",
            "Train Epoch: 10 [240/127 (47%)]\tLoss: 833.948853\n",
            "Train Epoch: 10 [320/127 (63%)]\tLoss: 107.818367\n",
            "Train Epoch: 10 [400/127 (79%)]\tLoss: 5262.859375\n",
            "Train Epoch: 10 [480/127 (94%)]\tLoss: 5201.974121\n",
            "Total loss 253109.31071090698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKvhXyq16twy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvK5pnsr6tw0",
        "colab_type": "text"
      },
      "source": [
        "# Congratulations!!! - Time to Join the Community!\n",
        "\n",
        "Congratulations on completing this notebook tutorial! If you enjoyed this and would like to join the movement toward privacy preserving, decentralized ownership of AI and the AI supply chain (data), you can do so in the following ways!\n",
        "\n",
        "### Star PySyft on GitHub\n",
        "\n",
        "The easiest way to help our community is just by starring the Repos! This helps raise awareness of the cool tools we're building.\n",
        "\n",
        "- [Star PySyft](https://github.com/OpenMined/PySyft)\n",
        "\n",
        "### Join our Slack!\n",
        "\n",
        "The best way to keep up to date on the latest advancements is to join our community! You can do so by filling out the form at [http://slack.openmined.org](http://slack.openmined.org)\n",
        "\n",
        "### Join a Code Project!\n",
        "\n",
        "The best way to contribute to our community is to become a code contributor! At any time you can go to PySyft GitHub Issues page and filter for \"Projects\". This will show you all the top level Tickets giving an overview of what projects you can join! If you don't want to join a project, but you would like to do a bit of coding, you can also look for more \"one off\" mini-projects by searching for GitHub issues marked \"good first issue\".\n",
        "\n",
        "- [PySyft Projects](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3AProject)\n",
        "- [Good First Issue Tickets](https://github.com/OpenMined/PySyft/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)\n",
        "\n",
        "### Donate\n",
        "\n",
        "If you don't have time to contribute to our codebase, but would still like to lend support, you can also become a Backer on our Open Collective. All donations go toward our web hosting and other community expenses such as hackathons and meetups!\n",
        "\n",
        "[OpenMined's Open Collective Page](https://opencollective.com/openmined)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPOxu69h6tw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}